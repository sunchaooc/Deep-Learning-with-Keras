  
from __future__ import print_function 
import numpy as np 
# from keras.datasets import mnist 
from keras.models import Sequential 
from keras.layers.core import Dense, Activation 
from keras.optimizers import SGD 
from keras.utils import np_utils 
np.random.seed(1671)#重复性设置

#网络和训练
NB_EPOCH=20
BATCH_SIZE =128
VERBOSE =1
NB_CLASSES=10#输出个数等于数字个数
OPTIMIZER=SGD()#SGD优化器，本章稍后介绍
N_HIDDEN = 128
VALIDATION_SPLIT=0.2#训练集中用作验证集的数据比例

def load_mnist():
    path = r'F:\1.ZHANGHAN\DATA\mnist.npz' #放置mnist.py的目录。注意斜杠
    f = np.load(path)
    x_train, y_train = f['x_train'], f['y_train']
    x_test, y_test = f['x_test'], f['y_test']
    f.close()
    return (x_train, y_train), (x_test, y_test)
    
(X_train,y_train),(X_test,y_test) = load_mnist()
# X_train是60000行28×28的数据，变形为60000×784
RESHAPED =784

X_train =X_train.reshape(60000,RESHAPED)
X_test =X_test.reshape(10000,RESHAPED)
X_train =X_train.astype('float32')
X_test =X_test.astype('float32')
#归一化
X_train/=255
X_test/=255
print(X_train.shape[1],'train samples')
print(X_test.shape[1],'test samples')

#将类向量转换为二值类别矩阵
Y_train=np_utils.to_categorical(y_train, NB_CLASSES)
Y_test=np_utils.to_categorical(y_test, NB_CLASSES)

#10个输出
#最后是softmax激活函数   ***增加了两个隐层***
model= Sequential()
model.add(Dense(N_HIDDEN,input_shape=(RESHAPED,)))
model.add(Activation('relu'))
model.add(Dense(N_HIDDEN))
model.add(Activation('relu'))
model.add(Dense(NB_CLASSES))
model.add(Activation('softmax'))
model.summary()

model.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy'])

history=model.fit(X_train,Y_train,
batch_size=BATCH_SIZE,epochs=NB_EPOCH,
verbose=VERBOSE, validation_split=VALIDATION_SPLIT)

score=model.evaluate(X_test, Y_test, verbose=VERBOSE)
print("Test loss：", score[0])
print('Test accuracy：', score[1])
